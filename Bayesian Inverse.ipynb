{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gauleg as gl \n",
    "import sympy as sp \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import Solver3 as sl \n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Delta Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cov_matrix(sigma, num_points):\n",
    "  sigma = (sigma ** 2) * np.eye(num_points)\n",
    "  return sigma\n",
    "\n",
    "\n",
    "def compute_basis_functions_at_x(x, mesh):\n",
    "    \"\"\"\n",
    "    Given an observation point x and the mesh, compute the two nonzero\n",
    "    finite element basis (hat) functions at x.\n",
    "    \n",
    "    Returns:\n",
    "      k: the index such that x is in [mesh[k], mesh[k+1]]\n",
    "      psi_left: the value of the basis function associated with mesh[k] at x.\n",
    "      psi_right: the value of the basis function associated with mesh[k+1] at x.\n",
    "    \"\"\"\n",
    "    mesh = np.asarray(mesh, dtype=float)\n",
    "    # Find the index k such that x is in [mesh[k], mesh[k+1]]\n",
    "    k = np.searchsorted(mesh, x) - 1\n",
    "    k = np.clip(k, 0, len(mesh) - 2)  # ensure k is valid\n",
    "    \n",
    "    psi_left = sl.phi_i(k, x, mesh)\n",
    "    psi_right = sl.phi_i(k+1, x, mesh)\n",
    "    return k, psi_left, psi_right\n",
    "\n",
    "# Example: Evaluate the FE solution at a set of observation points\n",
    "def fe_solution_at_obs(c_sol, mesh, x_obs):\n",
    "    \"\"\"\n",
    "    Compute the finite element solution at observation points x_obs,\n",
    "    given the nodal solution c_sol and the mesh.\n",
    "    \n",
    "    Parameters:\n",
    "      c_sol : array of nodal values (length N)\n",
    "      mesh  : array of node coordinates (length N)\n",
    "      x_obs : array of observation points\n",
    "      \n",
    "    Returns:\n",
    "      c_interp: array of interpolated FE solution values at x_obs.\n",
    "    \"\"\"\n",
    "    c_sol_full = sl.assemble_nodal_values(c_sol)\n",
    "    c_sol_full_array = np.asarray(c_sol_full).flatten()\n",
    "    c_interp = np.zeros_like(x_obs, dtype=float)\n",
    "    \n",
    "    for idx, x in enumerate(x_obs):\n",
    "        k, psi_left, psi_right = compute_basis_functions_at_x(x, mesh)\n",
    "        # The solution at x is the weighted average of the two nodal values\n",
    "        c_interp[idx] = c_sol_full_array[k] * psi_left + c_sol_full_array[k+1] * psi_right\n",
    "    return c_interp\n",
    "\n",
    "# Alternatively, if many observation points fall in the same element,\n",
    "# you could vectorize the process by grouping x_obs by element.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(observations_at_xi, num_points, sigma):\n",
    "    \"\"\"\n",
    "    Adds a normally distributed noise, theta\n",
    "    to observations from the forward solver.\n",
    "\n",
    "    Arguments:\n",
    "    observations_at_xi : observations at predetermined xi using interplotion. \n",
    "    num_points : how big your covariance matrix is \n",
    "\n",
    "    Returns:\n",
    "    Delta : Array of Noisy observations.\n",
    "    \n",
    "    \"\"\"\n",
    "    sigma = cov_matrix(sigma, num_points)\n",
    "    noise = np.random.multivariate_normal(np.zeros(num_points), sigma)\n",
    "    delta = observations_at_xi + noise \n",
    "    return delta\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Likelihood Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(observations, predicted, sigma, num_points) :\n",
    "    '''\n",
    "    For a set of predetermined points xi -- obtained via np.linspace,\n",
    "    this function defines the likelihood function \n",
    "\n",
    "    Arguments:\n",
    "    observations: Generated noisy observation using beta_true -- corresponds to y in literature\n",
    "    predicted: For a proposed beta_i, we compute the noisy observation using the forward solver \n",
    "    -- corresponds to g(beta_i) in literature\n",
    "\n",
    "    Returns: \n",
    "    Likelihood function that is proportional to the prior distribution\n",
    "    \n",
    "    '''\n",
    "    covariance_matrix = cov_matrix(sigma, num_points)\n",
    "    diff = predicted - observations\n",
    "    covariance_matrix_inv = np.linalg.inv(covariance_matrix) \n",
    "    val = 0.5 * diff.T @ covariance_matrix_inv @ diff\n",
    "    return val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_A(phi_0, phi_i, sigma):\n",
    "\n",
    "    val = np.exp(phi_0 - phi_i)\n",
    "    \n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MCMC_AFEM(beta_true, number_of_iter, burn_in, sigma, num_points): \n",
    "  '''\n",
    "  Builds a Markov Chain \n",
    "\n",
    "  Key Steps:\n",
    "  1. Initialise a choice of Beta, beta_0 \n",
    "  2. Compute likelihood of beta_0, using delta and beta_0_predicted\n",
    "  3. Initialise the loop.\n",
    "      - we propose a new beta_i from x* ~ Uniform(0.15, 0.85) and r ~ Uniform(0, 0.15)\n",
    "      - compute y_i and g(beta_i)\n",
    "      - compute likelihood using {y_i and g(beta_i)}\n",
    "      - set alpha = min{1, likelihood }\n",
    "  '''\n",
    "  # set seed \n",
    "  np.random.seed(72)\n",
    "  # range of uniform distribution \n",
    "  x_star_range = (0.3, 0.7) \n",
    "  r_range = (0.1, 0.2) \n",
    "  chain = []\n",
    "  ddof_list = 0\n",
    "  # compute delta \n",
    "  mesh_true , c_sol_true, ddof_true= sl.refinement_loop(0.00001, beta_true) \n",
    "  y_true = fe_solution_at_obs(c_sol_true, mesh_true, np.linspace(0.0, 1.0, num_points))\n",
    "  delta = add_noise(y_true, num_points, sigma)\n",
    "\n",
    "  # draw first copy of beta --> beta_0\n",
    "\n",
    "  beta_0 = np.array([\n",
    "          np.random.uniform(*x_star_range),\n",
    "          np.random.uniform(*r_range)\n",
    "      ])\n",
    "  print(\"Beta_0:\", beta_0)\n",
    "  \n",
    "  # initialise current observations and likelihood \n",
    "  mesh_0, c_sol_0, ddof_0 = sl.refinement_loop(0.001, beta = beta_0)\n",
    "  y_0 = fe_solution_at_obs(c_sol_0, mesh_0, np.linspace(0.0, 1.0, num_points))\n",
    "  phi_0 = phi(delta, y_0, sigma, num_points)\n",
    "  print(\"phi_0:\", phi_0)\n",
    "  \n",
    "  iter_count = 0\n",
    "  acceptance_count = 0 \n",
    "  acceptance_prob_history = []\n",
    "\n",
    "  for i in range(number_of_iter):\n",
    "    beta_proposal = np.array([\n",
    "        np.random.uniform(*x_star_range),\n",
    "        np.random.uniform(*r_range)\n",
    "    ])\n",
    "    print(\"beta proposal:\", beta_proposal)\n",
    "    mesh_proposal, c_sol_proposal, ddof_proposal = sl.refinement_loop(0.001, beta = beta_proposal)\n",
    "    y_proposal = fe_solution_at_obs(c_sol_proposal, mesh_proposal, np.linspace(0.0, 1.0, num_points))\n",
    "    phi_proposal = phi(delta, y_proposal, sigma, num_points)\n",
    "    print(\"phi proposal:\", phi_proposal)\n",
    "    # compute acceptance probability \n",
    "    A = compute_A(phi_0, phi_proposal, sigma)\n",
    "    acceptance_prob = min(1, A)\n",
    "    acceptance_prob_history.append(acceptance_prob)\n",
    "    print(\"acceptance probablity:\", acceptance_prob)\n",
    "    \n",
    "    # Accept or reject the proposal\n",
    "    if np.random.rand() < acceptance_prob:\n",
    "      beta_0 = beta_proposal # update the current state as the last accepted proposal\n",
    "      y_0 = y_proposal # update the current observations to the last accepted observation\n",
    "      phi_0 = phi_proposal\n",
    "      ddof_0 = ddof_proposal\n",
    "      acceptance_count += 1\n",
    "    \n",
    "    # Record the current state.\n",
    "    chain.append(beta_0.copy())\n",
    "    print(\"Chain length:\", len(chain))\n",
    "    ddof_list += ddof_0\n",
    "      \n",
    "  avg_ddof = ddof_list/len(chain)\n",
    "  chain = np.array(chain)\n",
    "  # Compute the MCMC estimate as the mean of the samples after burn-in.\n",
    "  beta_mcmc = np.mean(chain[burn_in:], axis=0)\n",
    "  \n",
    "  return chain, beta_mcmc, acceptance_count, avg_ddof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_of_iter = 10000\n",
    "# burn_in = 2000\n",
    "# sigma = 0.01\n",
    "# num_points = 100\n",
    "# beta_true = np.array([0.65, 0.15])\n",
    "\n",
    "# chain, beta_mcmc, acceptance_count, avg_dof = MCMC_AFEM(beta_true, number_of_iter, burn_in, sigma, num_points)\n",
    "# print(\"True beta:\", beta_true )\n",
    "# print(\"MCMC estimated beta:\", beta_mcmc)\n",
    "# print(\"Acceptance Count:\", acceptance_count)\n",
    "# print(\"ddof list:\", avg_dof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCMC(beta_true, number_of_iter, burn_in, sigma, num_points):\n",
    "    '''\n",
    "    Builds two MCMC chains (one using AFEM and one using a uniform mesh) using the same sequence of proposed Î².\n",
    "    \n",
    "    Parameters:\n",
    "      beta_true      : The true parameter used to generate the true data.\n",
    "      number_of_iter : Total number of MCMC iterations.\n",
    "      burn_in        : Number of iterations to discard as burn-in.\n",
    "      sigma          : Noise standard deviation.\n",
    "      num_points     : Number of observation points.\n",
    "    \n",
    "    Returns:\n",
    "      chain_afem, beta_mcmc_afem, acceptance_prob_history_afem, acceptance_count_afem,\n",
    "      chain_uniform, beta_mcmc_uniform, acceptance_prob_history_uniform, acceptance_count_uniform,\n",
    "      ddof_list\n",
    "    '''\n",
    "    np.random.seed(72)\n",
    "    \n",
    "    # Define proposal ranges:\n",
    "    x_star_range = (0.3, 0.7)\n",
    "    r_range = (0.1, 0.2)\n",
    "    \n",
    "    # Initialize lists to store chain history and diagnostic info:\n",
    "    chain_afem = []\n",
    "    chain_uniform = []\n",
    "    ddof_list = []\n",
    "    \n",
    "    # Compute true data (delta) for both forward models:\n",
    "    mesh_true, c_sol_true, ddof_true = sl.refinement_loop(0.00001, beta_true)\n",
    "    y_true = fe_solution_at_obs(c_sol_true, mesh_true, np.linspace(0.0, 1.0, num_points))\n",
    "    delta = add_noise(y_true, num_points, sigma)\n",
    "    \n",
    "    uniform_mesh = np.linspace(0.0, 1.0, 129)  # 128 elements => 129 nodes\n",
    "    c_sol_uniform_true, fvect_true_uniform = sl.solve_scF_once(uniform_mesh, beta_true)\n",
    "    y_true_uniform = fe_solution_at_obs(c_sol_uniform_true, uniform_mesh, np.linspace(0.0, 1.0, num_points))\n",
    "    delta_uniform = add_noise(y_true_uniform, num_points, sigma)\n",
    "    \n",
    "    # Draw initial beta (common initial state for both chains)\n",
    "    beta_0 = np.array([np.random.uniform(*x_star_range),\n",
    "                       np.random.uniform(*r_range)])\n",
    "    print(\"Beta_0:\", beta_0)\n",
    "    \n",
    "    # Initialize current state for AFEM chain:\n",
    "    beta_current_afem = beta_0.copy()\n",
    "    mesh_0, c_sol_0, ddof_0 = sl.refinement_loop(0.001, beta=beta_0)\n",
    "    y_current_afem = fe_solution_at_obs(c_sol_0, mesh_0, np.linspace(0.0, 1.0, num_points))\n",
    "    phi_current_afem = phi(delta, y_current_afem, sigma, num_points)\n",
    "    \n",
    "    # Initialize current state for Uniform FEM chain:\n",
    "    beta_current_uniform = beta_0.copy()\n",
    "    c_sol_0_uniform, fvect_0_uniform = sl.solve_scF_once(uniform_mesh, beta_0)\n",
    "    y_current_uniform = fe_solution_at_obs(c_sol_0_uniform, uniform_mesh, np.linspace(0.0, 1.0, num_points))\n",
    "    phi_current_uniform = phi(delta_uniform, y_current_uniform, sigma, num_points)\n",
    "    \n",
    "    acceptance_count_afem = 0\n",
    "    acceptance_count_uniform = 0\n",
    "    acceptance_prob_history_afem = []\n",
    "    acceptance_prob_history_uniform = []\n",
    "    \n",
    "    # MCMC loop:\n",
    "    for i in range(number_of_iter):\n",
    "        # Generate a common proposal for Î²:\n",
    "        beta_proposal = np.array([np.random.uniform(*x_star_range),\n",
    "                                  np.random.uniform(*r_range)])\n",
    "        print(\"beta proposal:\", beta_proposal)\n",
    "        \n",
    "        # Evaluate proposal with AFEM:\n",
    "        mesh_proposal_afem, c_sol_proposal_afem, ddof_proposal_afem = sl.refinement_loop(0.001, beta=beta_proposal)\n",
    "        y_proposal_afem = fe_solution_at_obs(c_sol_proposal_afem, mesh_proposal_afem, np.linspace(0.0, 1.0, num_points))\n",
    "        ddof_list.append((beta_proposal, ddof_proposal_afem))\n",
    "        phi_proposal_afem = phi(delta, y_proposal_afem, sigma, num_points)\n",
    "        print(\"phi proposal (AFEM):\", phi_proposal_afem)\n",
    "        A_afem = compute_A(phi_current_afem, phi_proposal_afem, sigma)\n",
    "        acceptance_prob_afem = min(1, A_afem)\n",
    "        acceptance_prob_history_afem.append(acceptance_prob_afem)\n",
    "        print(\"acceptance probability (AFEM):\", acceptance_prob_afem)\n",
    "        \n",
    "        # Evaluate proposal with Uniform FEM:\n",
    "        c_sol_proposal_uniform, fvect_proposal_uniform = sl.solve_scF_once(uniform_mesh, beta=beta_proposal)\n",
    "        y_proposal_uniform = fe_solution_at_obs(c_sol_proposal_uniform, uniform_mesh, np.linspace(0.0, 1.0, num_points))\n",
    "        phi_proposal_uniform = phi(delta_uniform, y_proposal_uniform, sigma, num_points)\n",
    "        print(\"phi proposal (Uniform FEM):\", phi_proposal_uniform)\n",
    "        A_uniform = compute_A(phi_current_uniform, phi_proposal_uniform, sigma)\n",
    "        acceptance_prob_uniform = min(1, A_uniform)\n",
    "        acceptance_prob_history_uniform.append(acceptance_prob_uniform)\n",
    "        print(\"acceptance probability (Uniform FEM):\", acceptance_prob_uniform)\n",
    "        \n",
    "        # For AFEM chain, use an independent random draw:\n",
    "        if np.random.rand() < acceptance_prob_afem:\n",
    "            beta_current_afem = beta_proposal.copy()\n",
    "            y_current_afem = y_proposal_afem.copy()\n",
    "            phi_current_afem = phi_proposal_afem\n",
    "            acceptance_count_afem += 1\n",
    "        \n",
    "        # For Uniform FEM chain, use another independent random draw:\n",
    "        if np.random.rand() < acceptance_prob_uniform:\n",
    "            beta_current_uniform = beta_proposal.copy()\n",
    "            y_current_uniform = y_proposal_uniform.copy()\n",
    "            phi_current_uniform = phi_proposal_uniform\n",
    "            acceptance_count_uniform += 1\n",
    "        \n",
    "        # Record the current states in their respective chains:\n",
    "        chain_afem.append(beta_current_afem.copy())\n",
    "        chain_uniform.append(beta_current_uniform.copy())\n",
    "        print(\"Chain lengths: AFEM =\", len(chain_afem), \", Uniform =\", len(chain_uniform))\n",
    "    \n",
    "    chain_afem = np.array(chain_afem)\n",
    "    chain_uniform = np.array(chain_uniform)\n",
    "    beta_mcmc_afem = np.mean(chain_afem[burn_in:], axis=0)\n",
    "    beta_mcmc_uniform = np.mean(chain_uniform[burn_in:], axis=0)\n",
    "    \n",
    "    return (chain_afem, beta_mcmc_afem, acceptance_prob_history_afem, acceptance_count_afem,\n",
    "            chain_uniform, beta_mcmc_uniform, acceptance_prob_history_uniform, acceptance_count_uniform,\n",
    "            ddof_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "# number_of_iter = 10000\n",
    "# burn_in = 2000\n",
    "# sigma = 0.01\n",
    "# num_points = 100\n",
    "# beta_true = np.array([0.65, 0.15])\n",
    "\n",
    "# # Call the MCMC function (assuming it has been defined and imported as above)\n",
    "# (chain_afem, beta_mcmc_afem, acceptance_prob_history_afem, acceptance_count_afem,\n",
    "#  chain_uniform, beta_mcmc_uniform, acceptance_prob_history_uniform, acceptance_count_uniform,\n",
    "#  ddof_list) = MCMC(beta_true, number_of_iter, burn_in, sigma, num_points)\n",
    "\n",
    "# # Print the results\n",
    "# print(\"True beta:\", beta_true)\n",
    "# print(\"AFEM recovered beta (mean after burn-in):\", beta_mcmc_afem)\n",
    "# print(\"Uniform FEM recovered beta (mean after burn-in):\", beta_mcmc_uniform)\n",
    "# print(\"AFEM acceptance count:\", acceptance_count_afem)\n",
    "# print(\"Uniform FEM acceptance count:\", acceptance_count_uniform)\n",
    "# print(\"AFEM acceptance probability history (first 10 samples):\", acceptance_prob_history_afem[:10])\n",
    "# print(\"Uniform FEM acceptance probability history (first 10 samples):\", acceptance_prob_history_uniform[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heat Map of Beta potential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "# # Parameters for the parameter grid (x* and r)\n",
    "# x_star_vals = np.linspace(0.3, 0.7, 20)   # More candidate x* values for finer resolution\n",
    "# r_vals = np.linspace(0.1, 0.2, 5)          # More candidate r values\n",
    "\n",
    "# # Create a mesh grid of parameter pairs\n",
    "# X, R = np.meshgrid(x_star_vals, r_vals)\n",
    "\n",
    "# # Global parameters (use the same parameters throughout)\n",
    "# epsilon = 1e-3       # Refinement tolerance\n",
    "# sigma = 0.01         # Noise standard deviation\n",
    "# num_points = 100     # Number of observation points\n",
    "\n",
    "# # Generate the \"true\" observation using beta_true\n",
    "# beta_true = np.array([0.65, 0.15])\n",
    "# mesh_true, c_sol_true, ddof = sl.refinement_loop(epsilon, beta_true)\n",
    "# y_true = fe_solution_at_obs(c_sol_true, mesh_true, np.linspace(0.0,1.0, num_points))\n",
    "# observations = y_true + add_noise(y_true, num_points, sigma)\n",
    "# true_potential = phi(y_true, y_true, sigma, num_points)\n",
    "\n",
    "# # Prepare an array to store the misfit potential values\n",
    "# potential = np.zeros_like(X)\n",
    "\n",
    "# # Loop over the grid of (x*, r) candidates\n",
    "# for i in range(X.shape[0]):\n",
    "#     for j in range(X.shape[1]):\n",
    "#         beta_candidate = np.array([X[i, j], R[i, j]])\n",
    "#         mesh_candidate, c_sol_candidate, ddof = sl.refinement_loop(epsilon, beta_candidate)\n",
    "#         y_candidate = fe_solution_at_obs(c_sol_candidate, mesh_candidate, np.linspace(0.0, 1.0, num_points))\n",
    "#         potential[i, j] = phi(y_true, y_candidate, sigma, num_points)\n",
    "\n",
    "# # Create the 2D contour plot with Plotly\n",
    "# fig = go.Figure(data=[\n",
    "#     go.Contour(\n",
    "#         x=x_star_vals,\n",
    "#         y=r_vals,\n",
    "#         z=potential,\n",
    "#         colorscale='turbid',\n",
    "#         contours=dict(showlabels=True),\n",
    "#         colorbar=dict(title=\"Potential\")\n",
    "#     ),\n",
    "#     go.Scatter(\n",
    "#         x=[beta_true[0]],\n",
    "#         y=[beta_true[1]],\n",
    "#         mode='markers',\n",
    "#         marker=dict(size=10, color='cyan'),\n",
    "#         name='True beta'\n",
    "#     )\n",
    "# ])\n",
    "\n",
    "# # Update layout with axis titles and overall title\n",
    "# fig.update_layout(\n",
    "#     title='2D Contour Plot of the Misfit Potential',\n",
    "#     xaxis_title='x*',\n",
    "#     yaxis_title='r',\n",
    "#     width=1000,\n",
    "#     height=1000\n",
    "# )\n",
    "\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 worker processes to run 4 chains.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "\n",
    "def run_single_chain(seed, beta_true, number_of_iter, burn_in, sigma, num_points):\n",
    "    # Print a start message for this chain.\n",
    "    print(f\"Starting chain with seed {seed}\", flush=True)\n",
    "    \n",
    "    # Set the random seed to ensure independent chains.\n",
    "    np.random.seed(seed)\n",
    "    result = MCMC(beta_true, number_of_iter, burn_in, sigma, num_points)\n",
    "    \n",
    "    # Print a finish message for this chain.\n",
    "    print(f\"Finished chain with seed {seed}\", flush=True)\n",
    "    return result  # expected to be (chain, beta_mcmc, acceptance_history, acceptance_count)\n",
    "\n",
    "def run_multiple_chains(n_chains, beta_true, number_of_iter, burn_in, sigma, num_points):\n",
    "    # Generate random seeds for each chain.\n",
    "    seeds = np.random.randint(0, 10000, size=n_chains)\n",
    "    # Create argument tuples for each chain.\n",
    "    args = [\n",
    "        (seed, beta_true, number_of_iter, burn_in, sigma, num_points)\n",
    "        for seed in seeds\n",
    "    ]\n",
    "    \n",
    "    # Limit the number of worker processes to the minimum of available cores and 4.\n",
    "    n_workers = min(mp.cpu_count(), 4)\n",
    "    print(f\"Using {n_workers} worker processes to run {n_chains} chains.\", flush=True)\n",
    "    \n",
    "    # Create a multiprocessing Pool and run chains in parallel.\n",
    "    with mp.Pool(processes=n_workers) as pool:\n",
    "        results = pool.starmap(run_single_chain, args)\n",
    "    \n",
    "    print(\"All chains completed.\", flush=True)\n",
    "    \n",
    "    # Unpack the results. Each result should be a tuple like\n",
    "    # (chain, beta_mcmc, acceptance_history, acceptance_count).\n",
    "    chains, beta_mcmcs, acceptance_histories, acceptance_counts = zip(*results)\n",
    "    return list(chains), list(beta_mcmcs), list(acceptance_histories), list(acceptance_counts)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    n_chains = 4  # For example, 8 chains will run in two rounds with 4 workers.\n",
    "    number_of_iter = 10000\n",
    "    burn_in = 5000\n",
    "    sigma = 0.01 \n",
    "    num_points = 100\n",
    "    beta_true = np.array([0.65,0.15])\n",
    "    \n",
    "    chains, beta_mcmcs, acceptance_histories, acceptance_counts = run_multiple_chains(\n",
    "        n_chains, beta_true, number_of_iter, burn_in, sigma, num_points\n",
    "    )\n",
    "    \n",
    "    print(\"True beta:\", beta_true)\n",
    "    print(\"MCMC estimated beta:\", beta_mcmcs)\n",
    "    print(\"Acceptance Probability History:\", acceptance_histories)\n",
    "    print(\"Acceptance Count:\", acceptance_counts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
