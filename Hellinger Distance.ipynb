{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gauleg as gl \n",
    "import sympy as sp \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#####################################\n",
    "###### INITIALISING PARAMETERS ######\n",
    "#####################################\n",
    "\n",
    "# def a0(x):\n",
    "#     return 2 + math.sin(2*math.pi *x)\n",
    "\n",
    "# def a0(x):\n",
    "#     if 0 <= x < xd:\n",
    "#         return 1\n",
    "#     elif 0.5 <= x <= 1:\n",
    "#         return 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def a0(x, beta):\n",
    "    \"\"\"\n",
    "    Computes the coefficient a0 at points x using the parameter beta.\n",
    "    \n",
    "    Parameters:\n",
    "        x (array-like): Spatial coordinates.\n",
    "        beta (tuple): (x_star, r) where x_star is the center of the interval \n",
    "                      and r is the half-width of the interval.\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Coefficient values; 2 if x is inside the interval, 1 otherwise.\n",
    "    \"\"\"\n",
    "    x_star, r = beta\n",
    "    x = np.asarray(x)\n",
    "    return np.where((x >= (x_star - r)) & (x <= (x_star + r)), 2.0, 1.0)\n",
    "\n",
    "\n",
    "# def f(x, beta):\n",
    "#     x = np.asarray(x)\n",
    "#     return a0(x, beta) * np.pi**2 * np.sin(np.pi * x)\n",
    "def f(x, beta):\n",
    "    x = np.asarray(x)\n",
    "    return np.ones_like(x)\n",
    "\n",
    "n2 =5\n",
    "\n",
    "####################################\n",
    "######### HELPER FUNCTIONS #########\n",
    "####################################\n",
    "\n",
    "    \n",
    "# helper functions\n",
    "def GL(x_left, x_right, func):\n",
    "    # Ensure xi and ci are NumPy arrays:\n",
    "    xi, ci = np.polynomial.legendre.leggauss(n2)\n",
    "    # Map the nodes from [-1,1] to [x_left, x_right]\n",
    "    x_mapped = 0.5 * ((x_right - x_left) * xi + (x_right + x_left))\n",
    "    # Evaluate the integrand at all mapped nodes (func must be vectorized or accept an array)\n",
    "    integrand_values = func(x_mapped)\n",
    "    # Compute the weighted sum using a dot-product and return the scaled result.\n",
    "    return 0.5 * (x_right - x_left) * np.dot(ci, integrand_values)\n",
    "\n",
    "def piecewise_GL(integrand, x_left, x_right, discont_points=None):\n",
    "    \"\"\"\n",
    "    Integrate 'integrand(x)' from x_left to x_right using Gauss-Legendre quadrature,\n",
    "    splitting the integration at any discontinuity points provided in discont_points.\n",
    "    \n",
    "    Parameters:\n",
    "      integrand      : function to integrate, which must accept a NumPy array.\n",
    "      x_left, x_right: the endpoints of the integration interval.\n",
    "      n2             : number of Gaussâ€“Legendre quadrature points.\n",
    "      discont_points : a list (or scalar) of discontinuity points in (x_left, x_right).\n",
    "                       If None or empty, no splitting is performed.\n",
    "    \n",
    "    Returns:\n",
    "      The value of the integral.\n",
    "    \"\"\"\n",
    "    # If no discontinuity is provided, do a single integration.\n",
    "    if discont_points is None or len(discont_points) == 0:\n",
    "        return GL(x_left=x_left, x_right=x_right, func=integrand)\n",
    "    \n",
    "    # Ensure discont_points is a list; if it's a scalar, convert it.\n",
    "    if not isinstance(discont_points, (list, tuple, np.ndarray)):\n",
    "        discont_points = [discont_points]\n",
    "    \n",
    "    # Filter out those discontinuity points that lie within (x_left, x_right)\n",
    "    splits = [p for p in discont_points if x_left < p < x_right]\n",
    "    \n",
    "    # Build the list of subinterval endpoints\n",
    "    pts = [x_left] + sorted(splits) + [x_right]\n",
    "    \n",
    "    # Integrate over each subinterval and sum the results.\n",
    "    total = 0.0\n",
    "    for i in range(len(pts) - 1):\n",
    "        total += GL(x_left=pts[i], x_right=pts[i+1], func=integrand)\n",
    "    return total\n",
    "\n",
    "def dphi_i_on_element(i, k, xlist):\n",
    "    \"\"\"\n",
    "    Return the (constant) slope of the i-th shape function on the k-th subinterval\n",
    "    [ x_k, x_{k+1} ] in a 1D mesh with nodes x_0 < ... < x_N.\n",
    "    \"\"\"\n",
    "    if i == k:\n",
    "        # node i is the left endpoint of the subinterval => slope from 1 at x_k down to 0 at x_{k+1}\n",
    "        dx = xlist[k+1] - xlist[k]\n",
    "        return -1.0 / dx\n",
    "    elif i == k+1:\n",
    "        # node i is the right endpoint => slope from 0 at x_k up to 1 at x_{k+1}\n",
    "        dx = xlist[k+1] - xlist[k]\n",
    "        return +1.0 / dx\n",
    "    else:\n",
    "        return 0.0\n",
    "def phi_i(i, x, mesh):\n",
    "    \"\"\"\n",
    "    Standard 1D hat (finite element) function.\n",
    "    This returns the value of the i-th hat function at x, given a mesh.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)  # Ensure x is a NumPy array.\n",
    "    N = len(mesh) - 1  # Number of elements; nodes are 0,1,...,N.\n",
    "    \n",
    "    if i == 0:\n",
    "        # For the left boundary, phi_0 is nonzero on [mesh[0], mesh[1]]\n",
    "        cond = (x >= mesh[0]) & (x <= mesh[1])\n",
    "        return np.where(cond, (mesh[1] - x) / (mesh[1] - mesh[0]), 0.0)\n",
    "    \n",
    "    elif i == N:\n",
    "        # For the right boundary, phi_N is nonzero on [mesh[N-1], mesh[N]]\n",
    "        cond = (x >= mesh[N-1]) & (x <= mesh[N])\n",
    "        return np.where(cond, (x - mesh[N-1]) / (mesh[N] - mesh[N-1]), 0.0)\n",
    "    \n",
    "    else:\n",
    "        # For an interior node i, the support is [mesh[i-1], mesh[i+1]]\n",
    "        cond = (x >= mesh[i-1]) & (x <= mesh[i+1])\n",
    "        # On the left subinterval [mesh[i-1], mesh[i]]\n",
    "        left_cond = (x >= mesh[i-1]) & (x <= mesh[i])\n",
    "        left_val = (x - mesh[i-1]) / (mesh[i] - mesh[i-1])\n",
    "        # On the right subinterval (mesh[i], mesh[i+1]]\n",
    "        right_cond = (x > mesh[i]) & (x <= mesh[i+1])\n",
    "        right_val = (mesh[i+1] - x) / (mesh[i+1] - mesh[i])\n",
    "        # Combine the two pieces:\n",
    "        val = np.where(left_cond, left_val, np.where(right_cond, right_val, 0.0))\n",
    "        return np.where(cond, val, 0.0)\n",
    "\n",
    "\n",
    "def assemble_nodal_values(C):\n",
    "    C = np.asarray(C) # Make sure C is 1D.\n",
    "    return np.concatenate(([[0.0]], C, [[0.0]]))\n",
    "\n",
    "\n",
    "def get_discont_points(x_left, x_right, beta):\n",
    "    \"\"\"\n",
    "    Compute the discontinuity points for the coefficient a0(x, beta) on the interval [x_left, x_right].\n",
    "\n",
    "    Parameters:\n",
    "      x_left, x_right : float\n",
    "          Endpoints of the integration interval.\n",
    "      beta : tuple\n",
    "          (x_star, r), where the discontinuity endpoints are x_star - r and x_star + r.\n",
    "    \n",
    "    Returns:\n",
    "      A list of discontinuity points (subset of [x_star - r, x_star + r]) that lie in (x_left, x_right).\n",
    "    \"\"\"\n",
    "    x_star, r_val = beta\n",
    "    pts = []\n",
    "    p1 = x_star - r_val\n",
    "    p2 = x_star + r_val\n",
    "    if x_left < p1 < x_right:\n",
    "        pts.append(p1)\n",
    "    if x_left < p2 < x_right:\n",
    "        pts.append(p2)\n",
    "    return pts\n",
    "\n",
    "\n",
    "def solve_scF_once(mesh, beta):\n",
    "    \"\"\"\n",
    "    Build and solve the system S*C = F for a single iteration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_list, m_list : lists of indices (e.g. polynomial degrees)\n",
    "    i_list         : indices for the piecewise-constant or piecewise-linear basis\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    C : Sympy Matrix\n",
    "        The solution vector for the unknowns.\n",
    "    \"\"\"\n",
    "    a0_with_beta = lambda x: a0(x, beta)\n",
    "\n",
    "    S0_mat = S0_ji(a0_with_beta, mesh, beta)         # Possibly a Sympy matrix\n",
    "    fvect = build_force_vector(f, mesh, 5, beta)  # Possibly a Sympy matrix\n",
    "\n",
    "    \n",
    "    # Extract interior (numerical slicing)\n",
    "    S_int = S0_mat[1:-1, 1:-1]\n",
    "    F_int = fvect[1:-1, :]\n",
    "    c_sol = np.linalg.solve(S_int.T, F_int) \n",
    "\n",
    "    return c_sol, fvect\n",
    "\n",
    "def refinement_loop(epsilon, beta):\n",
    "    \"\"\"\n",
    "    1) Start with initial mesh\n",
    "    2) Solve once\n",
    "    3) Estimate errors\n",
    "    4) If all errors < epsilon, done. Else refine, go back to step 2.\n",
    "    \"\"\"\n",
    "    ddof_list = []\n",
    "    approximation_list = []\n",
    "    mesh = np.linspace(0.0, 1.0, 5).tolist()\n",
    "    ddof = len(mesh) - 2\n",
    "\n",
    "    iteration_index = 0\n",
    "    while iteration_index < 30:\n",
    "        # Solve for c_sol on the current mesh\n",
    "        c_sol, f_sol = solve_scF_once(mesh=mesh, beta = beta)\n",
    "\n",
    "        nodal = assemble_nodal_values(c_sol)\n",
    "        approximation = nodal.T @ f_sol\n",
    "        approximation_list.append(approximation)\n",
    "\n",
    "        # Estimate the elementwise errors\n",
    "        errors = sum_of_error_list(mesh=mesh, nodal=nodal, beta= beta)\n",
    "\n",
    "        # Mark which elements to refine\n",
    "        # elements_to_refine = element_selection(errors=errors, epsilon=epsilon)\n",
    "        elements_to_refine = dorfler_marking(errors, 0.5)\n",
    "\n",
    "        # If no elements exceed threshold => done\n",
    "        if not elements_to_refine:\n",
    "            break\n",
    "        # Refine the mesh only on the marked elements.\n",
    "        new_mesh = element_refinement(mesh, elements_to_refine)\n",
    "\n",
    "        if new_mesh == mesh:\n",
    "            print(\"Mesh did not change upon refinement. Terminating.\")\n",
    "            break\n",
    "        mesh = new_mesh\n",
    "        iteration_index += 1\n",
    "        ddof += len(new_mesh) - 2\n",
    "        ddof_list.append(ddof)\n",
    "\n",
    "    true_approximation = approximation_list[-1].item()\n",
    "    error_list = []\n",
    "    for u_i in approximation_list:\n",
    "        error = true_approximation - u_i.item()\n",
    "        error_list.append(error)\n",
    "\n",
    "    # After loop, final solution is c_sol on final mesh\n",
    "    # Return everything, including the entire history\n",
    "    return mesh, c_sol, ddof_list, error_list, true_approximation\n",
    "\n",
    "\n",
    "###################################\n",
    "####### ASSEMBLY OF MATRIX  #######\n",
    "###################################\n",
    "\n",
    "# assembly of matrix S0 and F\n",
    "def S0_ji(func, mesh, beta):\n",
    "    \"\"\"\n",
    "    Assemble the stiffness matrix S0 using the coefficient function 'func' (which is beta-aware)\n",
    "    and the mesh. The integration splits at the discontinuity points derived from beta.\n",
    "    \"\"\"\n",
    "    N = len(mesh)\n",
    "    S0_mat = np.zeros((N, N), dtype=float)\n",
    "\n",
    "    # Assembly of diagonal entries:\n",
    "    for j in range(N):\n",
    "        diag_val = 0.0\n",
    "        # Contribution from the left subinterval [mesh[j-1], mesh[j]]\n",
    "        if j > 0:\n",
    "            x_left = mesh[j-1]\n",
    "            x_right = mesh[j]\n",
    "            def integrand_left(x):\n",
    "                return func(x) * (dphi_i_on_element(j, j-1, mesh))**2\n",
    "            diag_val += piecewise_GL(integrand_left, x_left, x_right,\n",
    "                                      discont_points=get_discont_points(x_left, x_right, beta))\n",
    "        # Contribution from the right subinterval [mesh[j], mesh[j+1]]\n",
    "        if j < N-1:\n",
    "            x_left = mesh[j]\n",
    "            x_right = mesh[j+1]\n",
    "            def integrand_right(x):\n",
    "                return func(x) * (dphi_i_on_element(j, j, mesh))**2\n",
    "            diag_val += piecewise_GL(integrand_right, x_left, x_right,\n",
    "                                      discont_points=get_discont_points(x_left, x_right, beta))\n",
    "        S0_mat[j, j] = diag_val\n",
    "\n",
    "    # Assembly of off-diagonal entries:\n",
    "    for j in range(1, N):\n",
    "        x_left = mesh[j-1]\n",
    "        x_right = mesh[j]\n",
    "        def integrand_off(x):\n",
    "            return func(x) * dphi_i_on_element(j-1, j-1, mesh) * dphi_i_on_element(j, j-1, mesh)\n",
    "        val = piecewise_GL(integrand_off, x_left, x_right,\n",
    "                           discont_points=get_discont_points(x_left, x_right, beta))\n",
    "        S0_mat[j, j-1] = val\n",
    "        S0_mat[j-1, j] = val  # Exploiting symmetry\n",
    "    \n",
    "    return S0_mat\n",
    "\n",
    "\n",
    "def build_force_vector(f, mesh, n2=5, beta=None):\n",
    "    \"\"\"\n",
    "    Assemble the force (load) vector F where\n",
    "         F[i] = âˆ« f(x, beta) * phi_i(x, mesh) dx,\n",
    "    splitting the integration at the discontinuity points derived from beta.\n",
    "    \n",
    "    Parameters:\n",
    "      f     : The source function, which now depends on beta.\n",
    "      mesh  : List of node coordinates.\n",
    "      n2    : Number of Gauss-Legendre points (if used in GL).\n",
    "      beta  : Parameter tuple (x_star, r) used in f.\n",
    "      \n",
    "    Returns:\n",
    "      F : A column vector (Sympy Matrix) of size (N+1) x 1.\n",
    "    \"\"\"\n",
    "    num_nodes = len(mesh)\n",
    "    F = np.zeros((num_nodes, 1), dtype=float)\n",
    "\n",
    "    \n",
    "    # Loop over each finite element function phi_i.\n",
    "    for i in range(num_nodes):\n",
    "        total = 0.0\n",
    "        # Left subinterval (if it exists)\n",
    "        if i > 0:\n",
    "            x_left  = mesh[i-1]\n",
    "            x_right = mesh[i]\n",
    "            def integrand_left(x):\n",
    "                return f(x, beta) * phi_i(i, x, mesh)\n",
    "            total += piecewise_GL(integrand_left, x_left, x_right,\n",
    "                                  discont_points=get_discont_points(x_left, x_right, beta))\n",
    "        # Right subinterval (if it exists)\n",
    "        if i < num_nodes - 1:\n",
    "            x_left  = mesh[i]\n",
    "            x_right = mesh[i+1]\n",
    "            def integrand_right(x):\n",
    "                return f(x, beta) * phi_i(i, x, mesh)\n",
    "            total += piecewise_GL(integrand_right, x_left, x_right,\n",
    "                                  discont_points=get_discont_points(x_left, x_right, beta))\n",
    "        \n",
    "        F[i, 0] = total\n",
    "    return F\n",
    "\n",
    "\n",
    "##############################################\n",
    "####### ERROR INDICATOR AND REFINEMENT #######\n",
    "##############################################\n",
    "\n",
    "\n",
    "# def r(mesh, e):\n",
    "#     \"\"\"\n",
    "#     Compute an approximation to the cell residual on element T = [mesh[e], mesh[e+1]].\n",
    "#     Since u_h is piecewise linear and a0 is constant on T (if T does not cross x=1/3),\n",
    "#     the derivative term is zero and we approximate r(x) by f(x).\n",
    "#     \"\"\"\n",
    "#     a, b = mesh[e], mesh[e+1]\n",
    "#     # Use a vectorized quadrature routine to approximate the L2 norm of f over T.\n",
    "#     rT = GL(a, b, f) / (b - a)\n",
    "#     return rT\n",
    "\n",
    "def r(x, mesh, uh, beta):\n",
    "    # 'uh' and 'mesh' are not strictly needed since a'(x)=0 almost everywhere.\n",
    "    # The interior PDE says r(x) = f(x) + slope*a'(x), and here r(x) is taken as f(x).\n",
    "    return f(x, beta)\n",
    "\n",
    "def element_residual_l2(mesh, e, beta):\n",
    "    \"\"\"\n",
    "    Compute the L2 norm squared of the cell residual on element T = [mesh[e], mesh[e+1]].\n",
    "    If r(x) is piecewise constant on T, then the L2 norm squared is (r_T)^2 * h.\n",
    "    When T is cut by a discontinuity, we integrate piecewise.\n",
    "    \"\"\"\n",
    "    a, b = mesh[e], mesh[e+1]\n",
    "    h = b - a\n",
    "    \n",
    "    discont_points = get_discont_points(a, b, beta)\n",
    "    \n",
    "    # Define the integrand that includes the dependence on beta.\n",
    "    def interior_integrand(x_val):\n",
    "        # Use r(x, ..., beta) so that the effect of beta is incorporated.\n",
    "        return r(x_val, None, None, beta)**2\n",
    "\n",
    "    # Integrate using piecewise_GL, splitting at the discontinuities if needed.\n",
    "    r_sq = piecewise_GL(interior_integrand, x_left=a, x_right=b, discont_points=discont_points)\n",
    "    return r_sq\n",
    "\n",
    "\n",
    "def slope_at_node(mesh, uh, i, side):\n",
    "    \"\"\"\n",
    "    Return the slope of the piecewise-linear FE solution uh on the element\n",
    "    adjacent to node i from the given side ('left' or 'right').\n",
    "    \"\"\"\n",
    "    n = len(mesh) - 1\n",
    "    if side == 'left':\n",
    "        if i == 0:\n",
    "            return 0.0\n",
    "        else:\n",
    "            dx = mesh[i] - mesh[i-1]\n",
    "            return (uh[i] - uh[i-1]) / dx\n",
    "    elif side == 'right':\n",
    "        if i >= n:\n",
    "            return 0.0\n",
    "        else:\n",
    "            dx = mesh[i+1] - mesh[i]\n",
    "            return (uh[i+1] - uh[i]) / dx\n",
    "    else:\n",
    "        raise ValueError(\"side must be 'left' or 'right'.\")\n",
    "\n",
    "def flux_jump(mesh, uh, i, a0_func):\n",
    "    \"\"\"\n",
    "    Compute the jump in the numerical flux at the node mesh[i] (assumed interior).\n",
    "    The flux is sigma = a0 * (approximate derivative). We define:\n",
    "      sigma_left  = a0(x_i^-) * slope on [mesh[i-1], mesh[i]],\n",
    "      sigma_right = a0(x_i^+) * slope on [mesh[i], mesh[i+1]].\n",
    "    The jump is then: j(x_i) = sigma_right - sigma_left.\n",
    "    \n",
    "    Parameters:\n",
    "      mesh    : array of node coordinates.\n",
    "      uh      : array of nodal values of the FE solution.\n",
    "      i       : the index of an interior node.\n",
    "      a0_func : a function to evaluate a0 at a given x.\n",
    "    \n",
    "    Returns:\n",
    "      float: the flux jump at node i.\n",
    "    \"\"\"\n",
    "    slope_left = slope_at_node(mesh, uh, i, 'left')\n",
    "    slope_right = slope_at_node(mesh, uh, i, 'right')\n",
    "    # Use a small perturbation to evaluate a0 on either side.\n",
    "    a_left  = a0_func(mesh[i] - 1e-9)\n",
    "    a_right = a0_func(mesh[i] + 1e-9)\n",
    "    sigma_left  = a_left * slope_left\n",
    "    sigma_right = a_right * slope_right\n",
    "    return sigma_right - sigma_left\n",
    "\n",
    "def sum_of_error(i, mesh, nodal, beta):\n",
    "    \"\"\"\n",
    "    Compute the error indicator for element i.\n",
    "    It consists of two parts:\n",
    "      - A residual term: h^2 * (L2 norm squared of the residual on element i).\n",
    "      - A boundary term: h * (flux jump at the element boundary)^2.\n",
    "    \"\"\"\n",
    "    x_left = mesh[i]\n",
    "    x_right = mesh[i+1]\n",
    "    h = x_right - x_left\n",
    "    # Residual error on the element (incorporating beta)\n",
    "    residual_sq = element_residual_l2(mesh, i, beta)\n",
    "    # Flux jump error. Note: pass a lambda that fixes beta in the coefficient function.\n",
    "    boundary_sq = flux_jump(mesh, nodal, i, lambda x: a0(x, beta)) ** 2\n",
    "    return h**2 * residual_sq + h * boundary_sq\n",
    "\n",
    "\n",
    "def sum_of_error_list(mesh, nodal, beta):\n",
    "    \"\"\"\n",
    "    Return the error indicator for each element, given the mesh, nodal values, and beta.\n",
    "    \"\"\"\n",
    "    return [sum_of_error(i, mesh, nodal, beta) for i in range(len(mesh) - 1)]\n",
    "\n",
    "\n",
    "def refine_mesh(mesh, element_index):\n",
    "    \"\"\"\n",
    "    Refine the element [mesh[element_index], mesh[element_index+1]] by bisection.\n",
    "    \"\"\"\n",
    "    x_left = mesh[element_index]\n",
    "    x_right = mesh[element_index+1]\n",
    "    midpoint = 0.5 * (x_left + x_right)\n",
    "    # Insert the midpoint after mesh[element_index]\n",
    "    return mesh[:element_index+1] + [midpoint] + mesh[element_index+1:]\n",
    "\n",
    "\n",
    "def element_selection(errors, epsilon):\n",
    "    \"\"\"\n",
    "    Given an array-like 'errors' (one error per element) and a tolerance epsilon,\n",
    "    return a list of element indices to refine (sorted in descending order).\n",
    "    \"\"\"\n",
    "    errors = np.asarray(errors)\n",
    "    print(errors.shape)\n",
    "    # Find all indices where error exceeds epsilon.\n",
    "    indices = np.nonzero(errors > epsilon)[0]\n",
    "    # Sort in descending order so that when refining, index shifts are avoided.\n",
    "    indices = np.sort(indices)[::-1]\n",
    "    return indices.tolist()\n",
    "\n",
    "def dorfler_marking(errors, theta):\n",
    "    errors = np.asarray(errors).flatten()\n",
    "    total_error = np.sum(errors)\n",
    "    sorted_indices = np.argsort(-errors)  # descending order\n",
    "    cum_sum = np.cumsum(errors[sorted_indices])\n",
    "    num_marked = np.searchsorted(cum_sum, theta * total_error) + 1\n",
    "    marked_indices = sorted_indices[:num_marked]\n",
    "    return marked_indices.tolist()\n",
    "\n",
    "def element_refinement(mesh, element_indices):\n",
    "    mesh_arr = np.array(mesh)\n",
    "    element_indices = np.array(element_indices, dtype=int)\n",
    "    # Compute midpoints for each marked element.\n",
    "    midpoints = 0.5 * (mesh_arr[element_indices] + mesh_arr[element_indices + 1]).flatten()\n",
    "    # Concatenate the original mesh with the new midpoints, then sort.\n",
    "    new_mesh = np.sort(np.concatenate((mesh_arr, midpoints)))\n",
    "    return new_mesh.tolist()\n",
    "\n",
    "def compute_basis_functions_at_x(x, mesh):\n",
    "    \"\"\"\n",
    "    Given an observation point x and the mesh, compute the two nonzero\n",
    "    finite element basis (hat) functions at x.\n",
    "    \n",
    "    Returns:\n",
    "      k: the index such that x is in [mesh[k], mesh[k+1]]\n",
    "      psi_left: the value of the basis function associated with mesh[k] at x.\n",
    "      psi_right: the value of the basis function associated with mesh[k+1] at x.\n",
    "    \"\"\"\n",
    "    mesh = np.asarray(mesh, dtype=float)\n",
    "    # Find the index k such that x is in [mesh[k], mesh[k+1]]\n",
    "    k = np.searchsorted(mesh, x) - 1\n",
    "    k = np.clip(k, 0, len(mesh) - 2)  # ensure k is valid\n",
    "    \n",
    "    psi_left = phi_i(k, x, mesh)\n",
    "    psi_right = phi_i(k+1, x, mesh)\n",
    "    return k, psi_left, psi_right\n",
    "\n",
    "def fe_solution_at_obs(c_sol, mesh, x_obs):\n",
    "    \"\"\"\n",
    "    Compute the finite element solution at observation points x_obs,\n",
    "    given the nodal solution c_sol and the mesh.\n",
    "    \n",
    "    Parameters:\n",
    "      c_sol : array of nodal values (length N)\n",
    "      mesh  : array of node coordinates (length N)\n",
    "      x_obs : array of observation points\n",
    "      \n",
    "    Returns:\n",
    "      c_interp: array of interpolated FE solution values at x_obs.\n",
    "    \"\"\"\n",
    "    c_sol_full = assemble_nodal_values(c_sol)\n",
    "    c_sol_full_array = np.asarray(c_sol_full).flatten()\n",
    "    c_interp = np.zeros_like(x_obs, dtype=float)\n",
    "    \n",
    "    for idx, x in enumerate(x_obs):\n",
    "        k, psi_left, psi_right = compute_basis_functions_at_x(x, mesh)\n",
    "        # The solution at x is the weighted average of the two nodal values\n",
    "        c_interp[idx] = c_sol_full_array[k] * psi_left + c_sol_full_array[k+1] * psi_right\n",
    "    return c_interp\n",
    "    \n",
    "def cov_matrix(sigma, num_points):\n",
    "  sigma = (sigma ** 2) * np.eye(num_points)\n",
    "  return sigma\n",
    "\n",
    "def add_noise(observations_at_xi, num_points, sigma):\n",
    "    \"\"\"\n",
    "    Adds a normally distributed noise, theta\n",
    "    to observations from the forward solver.\n",
    "\n",
    "    Arguments:\n",
    "    observations_at_xi : observations at predetermined xi using interplotion. \n",
    "    num_points : how big your covariance matrix is \n",
    "\n",
    "    Returns:\n",
    "    Delta : Array of Noisy observations.\n",
    "    \n",
    "    \"\"\"\n",
    "    sigma = cov_matrix(sigma, num_points)\n",
    "    noise = np.random.multivariate_normal(np.zeros(num_points), sigma)\n",
    "    delta = observations_at_xi + noise \n",
    "    return delta\n",
    "\n",
    "def phi(observations, predicted, sigma, num_points) :\n",
    "    '''\n",
    "    For a set of predetermined points xi -- obtained via np.linspace,\n",
    "    this function defines the likelihood function \n",
    "\n",
    "    Arguments:\n",
    "    observations: Generated noisy observation using beta_true -- corresponds to y in literature\n",
    "    predicted: For a proposed beta_i, we compute the noisy observation using the forward solver \n",
    "    -- corresponds to g(beta_i) in literature\n",
    "\n",
    "    Returns: \n",
    "    Likelihood function that is proportional to the prior distribution\n",
    "    \n",
    "    '''\n",
    "    covariance_matrix = cov_matrix(sigma, num_points)\n",
    "    diff = predicted - observations\n",
    "    covariance_matrix_inv = np.linalg.inv(covariance_matrix) \n",
    "    val = 0.5 * diff.T @ covariance_matrix_inv @ diff\n",
    "    return val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refinement_loop2(beta, num_dorfler):\n",
    "    \"\"\"\n",
    "    1) Start with an initial mesh\n",
    "    2) Solve once\n",
    "    3) Estimate errors\n",
    "    4) Refine if needed, or break if done\n",
    "    5) Return mesh, solution, and stored data\n",
    "    \"\"\"\n",
    "    ddof_list = []\n",
    "    approximation_list = []\n",
    "\n",
    "    # Initial mesh\n",
    "    mesh = np.linspace(0.0, 1.0, 5).tolist()\n",
    "    ddof = len(mesh) - 2\n",
    "\n",
    "    # We'll collect solution values at these observation points every iteration\n",
    "    obv_points = np.linspace(0.0, 1.0, 9)\n",
    "    obs_values_list = []  # will store arrays of length 9 (solution at each obs point)\n",
    "\n",
    "    iteration_index = 0\n",
    "    \n",
    "    while iteration_index < num_dorfler:\n",
    "        # 1) Solve for c_sol on the current mesh\n",
    "        c_sol, f_sol = solve_scF_once(mesh=mesh, beta=beta)\n",
    "\n",
    "        # 3) For your \"global\" approximation (e.g., a scalar measure)\n",
    "        nodal = assemble_nodal_values(c_sol)\n",
    "        approximation = nodal.T @ f_sol\n",
    "        approximation_list.append(approximation)\n",
    "\n",
    "        # 4) Estimate elementwise errors\n",
    "        errors = sum_of_error_list(mesh=mesh, nodal=nodal, beta=beta)\n",
    "\n",
    "        # 5) Mark which elements to refine\n",
    "        elements_to_refine = dorfler_marking(errors, 0.5)\n",
    "\n",
    "        if not elements_to_refine:\n",
    "            # no elements to refine => done\n",
    "            break\n",
    "\n",
    "        # Refine the mesh\n",
    "        new_mesh = element_refinement(mesh, elements_to_refine)\n",
    "        if new_mesh == mesh:\n",
    "            print(\"Mesh did not change upon refinement. Terminating.\")\n",
    "            break\n",
    "        obvs_at_obv_nodes = fe_solution_at_obs(c_sol, mesh, obv_points)\n",
    "        obs_values_list.append(obvs_at_obv_nodes)\n",
    "        mesh = new_mesh\n",
    "        iteration_index += 1\n",
    "\n",
    "        # Update degrees of freedom (assuming 1D interior points only)\n",
    "        ddof += len(new_mesh) - 2\n",
    "        ddof_list.append(ddof)\n",
    "\n",
    "    true_obs_values = obs_values_list[-1]  # array of length 9\n",
    "\n",
    "    # Return what you need\n",
    "    return (mesh, c_sol, ddof_list, true_obs_values,\n",
    "            obs_values_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Delta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_delta(num_dorfler, sigma, beta_ref, num_points):\n",
    "    delta_mesh, delta_c_sol, delta_ddof_list, delta_obs, obs_values_list_at_m = refinement_loop2(beta_ref, num_dorfler)\n",
    "    delta = add_noise(delta_obs, num_points, sigma)\n",
    "    return delta, obs_values_list_at_m\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Normalization Contants Z and Z^m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_parametric(observations, sigma, num_points, num_dorfler):\n",
    "    \"\"\"\n",
    "    Returns a function phi(r) = 0.5 * (predicted(r) - observations)^T * Cov^{-1} * (predicted(r) - observations)\n",
    "    where predicted(r) is obtained from refinement_loop2(..., num_dorfler).\n",
    "    \"\"\"\n",
    "    covariance_matrix = cov_matrix(sigma, num_points)\n",
    "    covariance_matrix_inv = np.linalg.inv(covariance_matrix)\n",
    "\n",
    "    def phi(r):\n",
    "        # Construct your parameter array (if needed)\n",
    "        beta_proposal = np.array([0.5, r])  # or however you define it\n",
    "\n",
    "        # refinement_loop2 returns (mesh, c_sol, ddof_list, final_predicted, predicted_list)\n",
    "        *_ , final_predicted, _  = refinement_loop2(\n",
    "            beta_proposal, num_dorfler\n",
    "        )\n",
    "\n",
    "        # final_predicted is presumably the solution at your observation points\n",
    "        diff = final_predicted - observations\n",
    "        val = 0.5 * diff.T @ covariance_matrix_inv @ diff\n",
    "        return val\n",
    "    return phi\n",
    "\n",
    "\n",
    "    # where to put the loop to compute Z^m? \n",
    "def compute_normalising_constant(I, phi_func, num_quad_points):\n",
    "    r_min = I[0]\n",
    "    r_max = I[1]\n",
    "    xi, ci = np.polynomial.legendre.leggauss(num_quad_points)\n",
    "    xs = 0.5 * (xi + 1) * (r_max - r_min) + r_min\n",
    "    cs = 0.5 * (r_max - r_min) * ci \n",
    "    integrand_vals = np.exp(-np.array([phi_func(r) for r in xs]))\n",
    "    integrand_vals *= 1/0.3\n",
    "    return np.sum(integrand_vals * cs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hellinger_distance(phi_ref, Z_ref, phi_M, Z_M, I, num_quad_points):\n",
    "    \"\"\"\n",
    "    Computes H^2 = 1 - 1/sqrt(Z_ref * Z_M) * \\int exp(-0.5[phi_ref(r) + phi_M(r)]) * prior(r) dr\n",
    "    Then returns H = sqrt(H^2).\n",
    "    \"\"\"\n",
    "    r_min, r_max = I\n",
    "    xi, ci = np.polynomial.legendre.leggauss(num_quad_points)\n",
    "    xs = 0.5 * (xi + 1) * (r_max - r_min) + r_min\n",
    "    cs = 0.5 * (r_max - r_min) * ci\n",
    "\n",
    "    # Evaluate 0.5*(phi_ref(r)+phi_M(r)) at each node\n",
    "    half_sum_vals = []\n",
    "    for r in xs:\n",
    "        val = 0.5 * (phi_ref(r) + phi_M(r))\n",
    "        half_sum_vals.append(val)\n",
    "\n",
    "    integrand_vals = np.exp(-np.array(half_sum_vals))\n",
    "    \n",
    "    # Multiply by uniform prior density on I\n",
    "    prior_density = 1.0 / (r_max - r_min)\n",
    "    integrand_vals *= prior_density\n",
    "\n",
    "    integral_val = np.sum(integrand_vals * cs)\n",
    "    \n",
    "    # H^2 = 1 - integral_val / sqrt(Z_ref * Z_M)\n",
    "    factor = integral_val / np.sqrt(Z_ref * Z_M)\n",
    "    H2 = 1.0 - factor\n",
    "    if H2 < 0.0:\n",
    "        # numerical guard if factor > 1 by tiny rounding\n",
    "        H2 = 0.0\n",
    "    H = np.sqrt(H2)\n",
    "    return H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_ref = np.array([0.5, 0.3]) \n",
    "I = (0.1, 0.4)  # prior domain  \n",
    "sigma = 0.01\n",
    "num_dorfler = 30 \n",
    "num_quad_points = 20\n",
    "num_points = 9\n",
    "M_list = list(range(10,20))  # refinement levels we want\n",
    "observations, observations_value_list_at_m = compute_delta(num_dorfler, sigma, beta_ref, num_points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M=10, Z=0.07674 Z^M=0.0779424,  Hellinger=0.0237997\n",
      "M=11, Z=0.07674 Z^M=0.0769339,  Hellinger=0.0153469\n",
      "M=12, Z=0.07674 Z^M=0.0766435,  Hellinger=0.0114325\n",
      "M=13, Z=0.07674 Z^M=0.0764414,  Hellinger=0.00690563\n",
      "M=14, Z=0.07674 Z^M=0.0764469,  Hellinger=0.00608498\n",
      "M=15, Z=0.07674 Z^M=0.0765014,  Hellinger=0.00444374\n",
      "M=16, Z=0.07674 Z^M=0.0765817,  Hellinger=0.00323236\n",
      "M=17, Z=0.07674 Z^M=0.0767156,  Hellinger=0.00187746\n",
      "M=18, Z=0.07674 Z^M=0.0767121,  Hellinger=0.00120833\n",
      "M=19, Z=0.07674 Z^M=0.0767589,  Hellinger=0.000571397\n"
     ]
    }
   ],
   "source": [
    "phi_ref = phi_parametric(observations, sigma, num_points, num_dorfler)\n",
    "z_ref = compute_normalising_constant(I, phi_ref, 20)\n",
    "\n",
    "for M in M_list:\n",
    "        phi_M = phi_parametric(observations, sigma, num_points, M)\n",
    "        Z_M   = compute_normalising_constant(I, phi_M, num_quad_points)\n",
    "\n",
    "\n",
    "        # 3) Compute Hellinger distance d_H(\\rho^{M,\\delta}, \\rho^\\delta)\n",
    "        H = compute_hellinger_distance(phi_ref, z_ref, phi_M, Z_M, I, num_quad_points)\n",
    "\n",
    "        print(f\"M={M}, Z={z_ref:.6g} Z^M={Z_M:.6g},  Hellinger={H:.6g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m M_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m]  \u001b[38;5;66;03m# refinement levels we want\u001b[39;00m\n\u001b[0;32m     52\u001b[0m observations, observations_value_list_at_m \u001b[38;5;241m=\u001b[39m compute_delta(num_dorfler, sigma, beta_ref, num_points)\n\u001b[1;32m---> 54\u001b[0m Z_ref, phi_ref, ZM_list, phiM_list, H_list \u001b[38;5;241m=\u001b[39m \u001b[43malgorithm_3_demo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_dorfler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Now you have all Z^M and the Hellinger distances\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[19], line 19\u001b[0m, in \u001b[0;36malgorithm_3_demo\u001b[1;34m(I, observations, sigma, num_points, M_list, num_dorfler, num_quad)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 1) Build reference posterior potential with large # of refinements\u001b[39;00m\n\u001b[0;32m     18\u001b[0m phi_ref \u001b[38;5;241m=\u001b[39m phi_parametric(observations, sigma, num_points, num_dorfler)\n\u001b[1;32m---> 19\u001b[0m Z_ref  \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_normalising_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_quad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# We'll store the results\u001b[39;00m\n\u001b[0;32m     22\u001b[0m list_of_ZM \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[14], line 33\u001b[0m, in \u001b[0;36mcompute_normalising_constant\u001b[1;34m(I, phi_func, num_quad_points)\u001b[0m\n\u001b[0;32m     31\u001b[0m xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (xi \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m (r_max \u001b[38;5;241m-\u001b[39m r_min) \u001b[38;5;241m+\u001b[39m r_min\n\u001b[0;32m     32\u001b[0m cs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (r_max \u001b[38;5;241m-\u001b[39m r_min) \u001b[38;5;241m*\u001b[39m ci \n\u001b[1;32m---> 33\u001b[0m integrand_vals \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([phi_func(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m xs]))\n\u001b[0;32m     34\u001b[0m integrand_vals \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m0.3\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(integrand_vals \u001b[38;5;241m*\u001b[39m cs)\n",
      "Cell \u001b[1;32mIn[14], line 33\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     31\u001b[0m xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (xi \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m (r_max \u001b[38;5;241m-\u001b[39m r_min) \u001b[38;5;241m+\u001b[39m r_min\n\u001b[0;32m     32\u001b[0m cs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (r_max \u001b[38;5;241m-\u001b[39m r_min) \u001b[38;5;241m*\u001b[39m ci \n\u001b[1;32m---> 33\u001b[0m integrand_vals \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[43mphi_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m xs]))\n\u001b[0;32m     34\u001b[0m integrand_vals \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m0.3\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(integrand_vals \u001b[38;5;241m*\u001b[39m cs)\n",
      "Cell \u001b[1;32mIn[14], line 14\u001b[0m, in \u001b[0;36mphi_parametric.<locals>.phi\u001b[1;34m(r)\u001b[0m\n\u001b[0;32m     11\u001b[0m beta_proposal \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0.5\u001b[39m, r])  \u001b[38;5;66;03m# or however you define it\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# refinement_loop2 returns (mesh, c_sol, ddof_list, final_predicted, predicted_list)\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;241m*\u001b[39m_ , final_predicted, _  \u001b[38;5;241m=\u001b[39m \u001b[43mrefinement_loop2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta_proposal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_dorfler\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# final_predicted is presumably the solution at your observation points\u001b[39;00m\n\u001b[0;32m     19\u001b[0m diff \u001b[38;5;241m=\u001b[39m final_predicted \u001b[38;5;241m-\u001b[39m observations\n",
      "Cell \u001b[1;32mIn[12], line 24\u001b[0m, in \u001b[0;36mrefinement_loop2\u001b[1;34m(beta, num_dorfler)\u001b[0m\n\u001b[0;32m     20\u001b[0m iteration_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m iteration_index \u001b[38;5;241m<\u001b[39m num_dorfler:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# 1) Solve for c_sol on the current mesh\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     c_sol, f_sol \u001b[38;5;241m=\u001b[39m \u001b[43msolve_scF_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# 3) For your \"global\" approximation (e.g., a scalar measure)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     nodal \u001b[38;5;241m=\u001b[39m assemble_nodal_values(c_sol)\n",
      "Cell \u001b[1;32mIn[11], line 193\u001b[0m, in \u001b[0;36msolve_scF_once\u001b[1;34m(mesh, beta)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03mBuild and solve the system S*C = F for a single iteration.\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03m    The solution vector for the unknowns.\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    191\u001b[0m a0_with_beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: a0(x, beta)\n\u001b[1;32m--> 193\u001b[0m S0_mat \u001b[38;5;241m=\u001b[39m \u001b[43mS0_ji\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma0_with_beta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m         \u001b[38;5;66;03m# Possibly a Sympy matrix\u001b[39;00m\n\u001b[0;32m    194\u001b[0m fvect \u001b[38;5;241m=\u001b[39m build_force_vector(f, mesh, \u001b[38;5;241m5\u001b[39m, beta)  \u001b[38;5;66;03m# Possibly a Sympy matrix\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# Extract interior (numerical slicing)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 287\u001b[0m, in \u001b[0;36mS0_ji\u001b[1;34m(func, mesh, beta)\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mintegrand_right\u001b[39m(x):\n\u001b[0;32m    286\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m func(x) \u001b[38;5;241m*\u001b[39m (dphi_i_on_element(j, j, mesh))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 287\u001b[0m         diag_val \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mpiecewise_GL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintegrand_right\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_right\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mdiscont_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_discont_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_right\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m     S0_mat[j, j] \u001b[38;5;241m=\u001b[39m diag_val\n\u001b[0;32m    291\u001b[0m \u001b[38;5;66;03m# Assembly of off-diagonal entries:\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 83\u001b[0m, in \u001b[0;36mpiecewise_GL\u001b[1;34m(integrand, x_left, x_right, discont_points)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# If no discontinuity is provided, do a single integration.\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m discont_points \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(discont_points) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_left\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_right\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_right\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintegrand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Ensure discont_points is a list; if it's a scalar, convert it.\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(discont_points, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n",
      "Cell \u001b[1;32mIn[11], line 58\u001b[0m, in \u001b[0;36mGL\u001b[1;34m(x_left, x_right, func)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mGL\u001b[39m(x_left, x_right, func):\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m# Ensure xi and ci are NumPy arrays:\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m     xi, ci \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolynomial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlegendre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleggauss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# Map the nodes from [-1,1] to [x_left, x_right]\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     x_mapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m ((x_right \u001b[38;5;241m-\u001b[39m x_left) \u001b[38;5;241m*\u001b[39m xi \u001b[38;5;241m+\u001b[39m (x_right \u001b[38;5;241m+\u001b[39m x_left))\n",
      "File \u001b[1;32mc:\\Users\\Admin\\PycharmProjects\\FYP\\.venv\\lib\\site-packages\\numpy\\polynomial\\legendre.py:1565\u001b[0m, in \u001b[0;36mleggauss\u001b[1;34m(deg)\u001b[0m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;66;03m# first approximation of roots. We use the fact that the companion\u001b[39;00m\n\u001b[0;32m   1563\u001b[0m \u001b[38;5;66;03m# matrix is symmetric in this case in order to obtain better zeros.\u001b[39;00m\n\u001b[0;32m   1564\u001b[0m c \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39mdeg \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m-> 1565\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[43mlegcompanion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1566\u001b[0m x \u001b[38;5;241m=\u001b[39m la\u001b[38;5;241m.\u001b[39meigvalsh(m)\n\u001b[0;32m   1568\u001b[0m \u001b[38;5;66;03m# improve roots by one application of Newton\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\PycharmProjects\\FYP\\.venv\\lib\\site-packages\\numpy\\polynomial\\legendre.py:1455\u001b[0m, in \u001b[0;36mlegcompanion\u001b[1;34m(c)\u001b[0m\n\u001b[0;32m   1453\u001b[0m top \u001b[38;5;241m=\u001b[39m mat\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m::n\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1454\u001b[0m bot \u001b[38;5;241m=\u001b[39m mat\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[n::n\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m-> 1455\u001b[0m top[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39mscl[:n\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39mscl[\u001b[38;5;241m1\u001b[39m:n]\n\u001b[0;32m   1456\u001b[0m bot[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m top\n\u001b[0;32m   1457\u001b[0m mat[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m (c[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39mc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m*\u001b[39m(scl\u001b[38;5;241m/\u001b[39mscl[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m*\u001b[39m(n\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mn \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def algorithm_3_demo(I, observations, sigma, num_points, M_list, num_dorfler, num_quad=20):\n",
    "    \"\"\"\n",
    "    I: tuple (r_min, r_max)\n",
    "    observations: measured data\n",
    "    sigma: noise level\n",
    "    num_points: # of observation points\n",
    "    M_list: list of refinement levels, e.g. [1,2,3,4,5]\n",
    "    num_quad: Gauss-Legendre quadrature points\n",
    "\n",
    "    Returns:\n",
    "        Z_ref, phi_ref,\n",
    "        list_of_ZM, list_of_phiM,\n",
    "        list_of_hellinger\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Build reference posterior potential with large # of refinements\n",
    "\n",
    "    phi_ref = phi_parametric(observations, sigma, num_points, num_dorfler)\n",
    "    Z_ref  = compute_normalising_constant(I, phi_ref, num_quad)\n",
    "\n",
    "    # We'll store the results\n",
    "    list_of_ZM = []\n",
    "    list_of_phiM = []\n",
    "    list_of_H = []\n",
    "\n",
    "    # 2) For each M in M_list, compute Z^M and then Hellinger distance\n",
    "    for M in M_list:\n",
    "        phi_M = phi_parametric(observations, sigma, num_points, M)\n",
    "        Z_M   = compute_normalising_constant(I, phi_M, num_quad)\n",
    "        list_of_ZM.append(Z_M)\n",
    "        list_of_phiM.append(phi_M)\n",
    "\n",
    "        # 3) Compute Hellinger distance d_H(\\rho^{M,\\delta}, \\rho^\\delta)\n",
    "        H = compute_hellinger_distance(phi_ref, Z_ref, phi_M, Z_M, I, num_quad_points=num_quad)\n",
    "        list_of_H.append(H)\n",
    "        print(f\"M={M},  Z^M={Z_M:.6g},  Hellinger={H:.6g}\")\n",
    "\n",
    "    return Z_ref, phi_ref, list_of_ZM, list_of_phiM, list_of_H\n",
    "\n",
    "\n",
    "# ---------------- EXAMPLE USAGE ---------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    import numpy as np\n",
    "\n",
    "    beta_ref = np.array([0.5, 0.3]) \n",
    "    I = (0.1, 0.4)  # prior domain\n",
    "    observations = np.array([...])  # your measured data at 'num_points' locations\n",
    "    sigma = 0.01\n",
    "    num_dorfler = 30 \n",
    "    num_quad_points = 20\n",
    "    num_points = 9\n",
    "    M_list = [1, 2, 3, 4, 5]  # refinement levels we want\n",
    "    observations, observations_value_list_at_m = compute_delta(num_dorfler, sigma, beta_ref, num_points)\n",
    "\n",
    "    Z_ref, phi_ref, ZM_list, phiM_list, H_list = algorithm_3_demo(I, observations, sigma, num_points, M_list, num_dorfler)\n",
    "    # Now you have all Z^M and the Hellinger distances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute derivations "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
